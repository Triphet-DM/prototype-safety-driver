from picamera2 import Picamera2
import cv2
import numpy as np
from flask import Flask, Response
import time
import csv
import os
import psutil

# Config
FACE_CASCADE_FILE = 'haarcascade_frontalface_default.xml'
CAM_RESOLUTION = (320, 240)
FPS = 10
DETECT_DELAY = 0.7
CSV_FILE = 'head_pose_log.csv'
CSV_INTERVAL = 1.0

face_cascade = cv2.CascadeClassifier(FACE_CASCADE_FILE)

# Head Pose model points
model_points = np.array([
    (0.0, 0.0, 0.0),
    (0.0, -330.0, -65.0),
    (-225.0, 170.0, -135.0),
    (225.0, 170.0, -135.0),
    (-150.0, -150.0, -125.0),
    (150.0, -150.0, -125.0)
], dtype="double")

picam2 = Picamera2()
config = picam2.create_preview_configuration(main={"size": CAM_RESOLUTION})
picam2.configure(config)
picam2.start()
time.sleep(1)

app = Flask(__name__)
last_detect_time = 0
last_csv_time = 0
frame_time = time.time()
face_count = 0
headpose_count = 0

# Prepare CSV
if not os.path.exists(CSV_FILE):
    with open(CSV_FILE,mode='w',newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['timestamp','faces_detected','yaw','pitch','face_count','headpose_count'])

def gen_frames():
    global last_detect_time, last_csv_time, frame_time, face_count, headpose_count
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    while True:
        frame = picam2.capture_array()
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray = clahe.apply(gray)
        gray = cv2.equalizeHist(gray)

        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5)
        yaw, pitch = 0.0, 0.0

        if len(faces) > 0:
            face_count += 1
            (x,y,w,h) = faces[0]
            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)

            # Head Pose
            image_points = np.array([
                (x + w/2, y + h/2 - h/6),
                (x + w/2, y + h - h/10),
                (x + w/4, y + h/3),
                (x + 3*w/4, y + h/3),
                (x + w/3, y + 3*h/4),
                (x + 2*w/3, y + 3*h/4)
            ], dtype="double")

            focal_length = frame.shape[1]
            center = (frame.shape[1]/2, frame.shape[0]/2)
            camera_matrix = np.array([[focal_length,0,center[0]],[0,focal_length,center[1]],[0,0,1]],dtype="double")
            dist_coeffs = np.zeros((4,1))

            success, rotation_vector, translation_vector = cv2.solvePnP(
                model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE
            )

            if success:
                headpose_count += 1
                rmat,_ = cv2.Rodrigues(rotation_vector)
                proj_matrix = np.hstack((rmat,translation_vector))
                _,_,_,_,_,_,eulerAngles = cv2.decomposeProjectionMatrix(proj_matrix)
                pitch,yaw,roll = [float(a) for a in eulerAngles]

                nose_end,_ = cv2.projectPoints(np.array([(0.0,0.0,500.0)]),
                                               rotation_vector, translation_vector, camera_matrix, dist_coeffs)
                p1 = (int(image_points[0][0]), int(image_points[0][1]))
                p2 = (int(nose_end[0][0][0]), int(nose_end[0][0][1]))
                cv2.line(frame,p1,p2,(0,0,255),2)

        current_time = time.time()
        if current_time - last_detect_time > DETECT_DELAY:
            fps_real = 1 / (current_time - frame_time)
            frame_time = current_time
            cpu_load = psutil.cpu_percent()
            try:
                with open("/sys/class/thermal/thermal_zone0/temp","r") as f:
                    cpu_temp = float(f.read())/1000
            except:
                cpu_temp = 0.0

            print(f"Face: {'Detected' if len(faces)>0 else 'Not detected'} ({face_count}) | Yaw: {yaw:.1f} | Pitch: {pitch:.1f} | HeadPose: {headpose_count} | CPU: {cpu_load:.1f}% | Temp: {cpu_temp:.1f}Â°C | FPS: {fps_real:.1f}")
            last_detect_time = current_time

        if current_time - last_csv_time > CSV_INTERVAL:
            with open(CSV_FILE,mode='a',newline='') as f:
                writer = csv.writer(f)
                writer.writerow([time.strftime('%Y-%m-%d %H:%M:%S'), len(faces), f"{yaw:.1f}", f"{pitch:.1f}", face_count, headpose_count])
            last_csv_time = current_time

        ret, buffer = cv2.imencode('.jpg', frame)
        if not ret:
            continue
        yield (b'--frame\r\n'+b'Content-Type: image/jpeg\r\n\r\n'+buffer.tobytes()+b'\r\n')
        time.sleep(1/FPS)

@app.route('/video_feed')
def video_feed():
    return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/')
def index():
    return '''
    <html>
        <head><title>Head Pose Detection + CSV</title></head>
        <body>
            <h1>Head Pose Detection</h1>
            <img src="/video_feed" width="320" height="240">
        </body>
    </html>
    '''

if __name__=="__main__":
    print("Starting Head Pose Detection. Open http://<Pi_IP>:5000")
    app.run(host='0.0.0.0', port=5000, debug=False)
